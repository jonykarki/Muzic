{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
    }
   ],
   "source": [
    "# Character level lyrics generation using RNNs (LSTM)\n",
    "import sys, os, random, string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "import CharlyricsDataset\n",
    "from RNN import RNN\n",
    "import glob\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# interactive mode\n",
    "plt.ion()\n",
    "\n",
    "from pathlib import Path\n",
    "from config import config\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CharlyricsDataset.CharLyricsDataset(config.DATA.LYRICS, config.TRAIN.MAX_LEN)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.TRAIN.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(utils.get_total_characters(), config.TRAIN.HIDDEN_SIZE, config.TRAIN.LSTM_N_LAYERS, utils.get_total_characters()).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.TRAIN.LEARNING_RATE)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training Epoch 0\nTotal Loss 113.32127783965319\nTraining Epoch 1\nTotal Loss 113.29228707451374\nTraining Epoch 2\nTotal Loss 113.26473779741674\nTraining Epoch 3\nTotal Loss 113.23847838480026\nTraining Epoch 4\nTotal Loss 113.21343167554588\nTraining Epoch 5\nTotal Loss 113.1894790230319\nTraining Epoch 6\nTotal Loss 113.16661517336965\nTraining Epoch 7\nTotal Loss 113.14476598206907\nTraining Epoch 8\nTotal Loss 113.12390672866255\nTraining Epoch 9\nTotal Loss 113.1039573180303\n"
    }
   ],
   "source": [
    "for epoch in range(config.TRAIN.EPOCHS):\n",
    "    total_loss = 0\n",
    "    print(f\"Training Epoch {epoch}\")\n",
    "    for _, batch in enumerate(train_loader):\n",
    "        model.zero_grad()\n",
    "        input_seq, output_seq = batch\n",
    "\n",
    "        input_seq = input_seq.to(device)\n",
    "        output_seq = output_seq.to(device)\n",
    "        loss = 0\n",
    "\n",
    "        # vectorize this\n",
    "        for c in range(config.TRAIN.MAX_LEN):\n",
    "            output = model(input_seq[:, c])\n",
    "            loss += loss_fn(output, output_seq[:, c])\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Total Loss {total_loss/(config.TRAIN.MAX_LEN * len(train_loader))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'\\x0c'"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}