{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
    }
   ],
   "source": [
    "# Character level lyrics generation using RNNs (LSTM)\n",
    "import sys, os, random, string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import CharlyricsDataset\n",
    "from RNN import RNN\n",
    "import glob\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# interactive mode\n",
    "plt.ion()\n",
    "\n",
    "from pathlib import Path\n",
    "from config import config\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CharlyricsDataset.CharLyricsDataset(config.DATA.LYRICS, config.TRAIN.MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "53772"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.TRAIN.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1680"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(utils.get_total_characters(), config.TRAIN.HIDDEN_SIZE, config.TRAIN.LSTM_N_LAYERS, utils.get_total_characters()).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.TRAIN.LEARNING_RATE)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b384dfdc8a4d4577a228bb9e9a0bdead",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Training: Epoch 1/10', max=12.0, style=ProgressStyle(desc…"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nEpoch 1: Total Loss 344.36492004159425\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845124239ed846b798befc088b5372ae",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Training: Epoch 2/10', max=12.0, style=ProgressStyle(desc…"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nEpoch 2: Total Loss 343.9445794124405\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d173940f304bccaa2d1bf9a37018da",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Training: Epoch 3/10', max=12.0, style=ProgressStyle(desc…"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nEpoch 3: Total Loss 343.5620702658097\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4b16e5797c4923b7a787dcc7166039",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Training: Epoch 4/10', max=12.0, style=ProgressStyle(desc…"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nEpoch 4: Total Loss 343.2658296155598\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885fafbf69f14211a28e6127e4d10948",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Training: Epoch 5/10', max=12.0, style=ProgressStyle(desc…"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nEpoch 5: Total Loss 343.24492005017066\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8f0e13497a44b4ae632af9bdef5b94",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Training: Epoch 6/10', max=12.0, style=ProgressStyle(desc…"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nEpoch 6: Total Loss 343.28807777421343\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51bdd90d0b594b1b9c8cc66a9d0fab1b",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Training: Epoch 7/10', max=12.0, style=ProgressStyle(desc…"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nEpoch 7: Total Loss 343.2297369449006\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48b955a12cb470ea3f4fd6d3f0595d2",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Training: Epoch 8/10', max=12.0, style=ProgressStyle(desc…"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nEpoch 8: Total Loss 343.16170631491474\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb345215c28e408a89a278bd6c7a14a7",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Training: Epoch 9/10', max=12.0, style=ProgressStyle(desc…"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nEpoch 9: Total Loss 343.10349785791504\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9786d41c395c433fb348c490f5a10499",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Training: Epoch 10/10', max=12.0, style=ProgressStyle(des…"
     },
     "metadata": {}
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-582fe2e2f399>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# tq.set_postfix(loss=loss.item())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# batch-gradient-descent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(config.TRAIN.EPOCHS):\n",
    "    model.train()\n",
    "    tq = tqdm(train_loader, total=len(train_loader), desc=f\"Training: Epoch {epoch+1}/{config.TRAIN.EPOCHS}\")\n",
    "    total_loss = 0\n",
    "\n",
    "    for _, batch in enumerate(tq):\n",
    "        model.zero_grad()\n",
    "        input_seq, output_seq = batch\n",
    "\n",
    "        input_seq = input_seq.to(device)\n",
    "        output_seq = output_seq.to(device)\n",
    "        loss = 0\n",
    "\n",
    "        # vectorize this\n",
    "        for c in range(config.TRAIN.MAX_LEN):\n",
    "            output = model(input_seq[:, c])\n",
    "            loss += loss_fn(output, output_seq[:, c])\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        # tq.set_postfix(loss=loss.item())\n",
    "        # batch-gradient-descent\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Total Loss {total_loss/(config.TRAIN.MAX_LEN * len(train_loader))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prime=\"B\", total_len=300, temp=0.85):\n",
    "    generated_text = prime\n",
    "    last_char = prime\n",
    "    \n",
    "    for c in range(total_len):\n",
    "        input_char = torch.LongTensor(utils.char_to_label(last_char)).to(device)\n",
    "        out = model(input_char)\n",
    "        top_char = np.argmax(out.detach().cpu())\n",
    "        predicted = string.printable[top_char]\n",
    "        generated_text += predicted\n",
    "        last_char = predicted\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'be t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t '"
     },
     "metadata": {},
     "execution_count": 125
    }
   ],
   "source": [
    "generate(\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}