{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
    }
   ],
   "source": [
    "# Character level lyrics generation using RNNs (LSTM)\n",
    "import sys, os, random, string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import CharlyricsDataset\n",
    "from RNN import RNN\n",
    "import glob\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# interactive mode\n",
    "plt.ion()\n",
    "\n",
    "from pathlib import Path\n",
    "from config import config\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CharlyricsDataset.CharLyricsDataset(config.DATA.LYRICS, config.TRAIN.MAX_LEN)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.TRAIN.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(utils.get_total_characters(), config.TRAIN.HIDDEN_SIZE, config.TRAIN.LSTM_N_LAYERS, utils.get_total_characters()).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.TRAIN.LEARNING_RATE)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1: Total Loss 115.031648048684\nEpoch 2: Total Loss 114.83985180836171\nEpoch 3: Total Loss 114.684381830208\nEpoch 4: Total Loss 114.55340315427631\nEpoch 5: Total Loss 114.46677482873201\nEpoch 6: Total Loss 114.38979147985577\nEpoch 7: Total Loss 114.29749544911087\nEpoch 8: Total Loss 114.23054692912847\nEpoch 9: Total Loss 114.19710261147469\nEpoch 10: Total Loss 114.10984837304801\nEpoch 11: Total Loss 114.06276754789054\nEpoch 12: Total Loss 114.01070972368122\nEpoch 13: Total Loss 113.96171462997795\nEpoch 14: Total Loss 113.91296009432524\nEpoch 15: Total Loss 113.87741595748813\nEpoch 16: Total Loss 113.83976903643459\nEpoch 17: Total Loss 113.79971875846385\nEpoch 18: Total Loss 113.77591032791882\nEpoch 19: Total Loss 113.73835018601268\nEpoch 20: Total Loss 113.70337689045817\nEpoch 21: Total Loss 113.67475814718753\nEpoch 22: Total Loss 113.64347309038043\nEpoch 23: Total Loss 113.619046921283\nEpoch 24: Total Loss 113.57928955748677\nEpoch 25: Total Loss 113.56409799948335\nEpoch 26: Total Loss 113.53908464729786\nEpoch 27: Total Loss 113.51489124018698\nEpoch 28: Total Loss 113.49253365974873\nEpoch 29: Total Loss 113.47561929728836\nEpoch 30: Total Loss 113.45818450625985\nEpoch 31: Total Loss 113.43563286796213\nEpoch 32: Total Loss 113.41932126339525\nEpoch 33: Total Loss 113.40035908643156\nEpoch 34: Total Loss 113.38018222749233\nEpoch 35: Total Loss 113.36560047488659\nEpoch 36: Total Loss 113.35053607583046\nEpoch 37: Total Loss 113.33262451909482\nEpoch 38: Total Loss 113.3224235059321\nEpoch 39: Total Loss 113.30968124639243\nEpoch 40: Total Loss 113.29926572587341\nEpoch 41: Total Loss 113.2881078370288\nEpoch 42: Total Loss 113.27888950940222\nEpoch 43: Total Loss 113.26650059457869\nEpoch 44: Total Loss 113.25889986466616\nEpoch 45: Total Loss 113.24644049938769\nEpoch 46: Total Loss 113.23128954734653\nEpoch 47: Total Loss 113.21931227635592\nEpoch 48: Total Loss 113.21017762642354\nEpoch 49: Total Loss 113.18623580563813\nEpoch 50: Total Loss 113.17545871451497\n"
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    # tq = tqdm(train_loader, total=len(train_loader), desc=f\"Training: Epoch {epoch+1}/{config.TRAIN.EPOCHS}\")\n",
    "    total_loss = 0\n",
    "\n",
    "    for _, batch in enumerate(train_loader):\n",
    "        model.zero_grad()\n",
    "        input_seq, output_seq = batch\n",
    "\n",
    "        input_seq = input_seq.to(device)\n",
    "        output_seq = output_seq.to(device)\n",
    "        loss = 0\n",
    "\n",
    "        # vectorize this\n",
    "        for c in range(config.TRAIN.MAX_LEN):\n",
    "            output = model(input_seq[:, c])\n",
    "            loss += loss_fn(output, output_seq[:, c])\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        # tq.set_postfix(loss=loss.item())\n",
    "        # batch-gradient-descent\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Total Loss {total_loss/(config.TRAIN.MAX_LEN * len(train_loader))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prime=\"B\", total_len=300, temp=0.85):\n",
    "    generated_text = prime\n",
    "    last_char = prime\n",
    "    \n",
    "    for c in range(total_len):\n",
    "        input_char = torch.LongTensor(utils.char_to_label(last_char)).to(device)\n",
    "        out = model(input_char)\n",
    "        top_char = np.argmax(out.detach().cpu())\n",
    "        predicted = string.printable[top_char]\n",
    "        generated_text += predicted\n",
    "        last_char = predicted\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'re the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the th'"
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "generate(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}