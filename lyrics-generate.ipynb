{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
    }
   ],
   "source": [
    "# Character level lyrics generation using RNNs (LSTM)\n",
    "import sys, os, random, string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import CharlyricsDataset\n",
    "from RNN import RNN\n",
    "import glob\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# interactive mode\n",
    "plt.ion()\n",
    "\n",
    "from pathlib import Path\n",
    "from config import config\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CharlyricsDataset.CharLyricsDataset(config.DATA.LYRICS, config.TRAIN.MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "459065"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.TRAIN.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "585"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(utils.get_total_characters(), config.TRAIN.HIDDEN_SIZE, config.TRAIN.LSTM_N_LAYERS, utils.get_total_characters()).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.TRAIN.LEARNING_RATE)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f99a1c0aede4a6ebd3cbae47a573cea",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Training: Epoch 1/10', max=840.0, style=ProgressStyle(des…"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nEpoch 1: Total Loss 374.75824603131036\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6be7987d4f44ba88de216385f4a32f8",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Training: Epoch 2/10', max=840.0, style=ProgressStyle(des…"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nEpoch 2: Total Loss 369.94710677867323\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd19792c445460385ad018fd4e2abf0",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Training: Epoch 3/10', max=840.0, style=ProgressStyle(des…"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nEpoch 3: Total Loss 369.54836229180154\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de3005c5cae4bdcaa34945c6cce01f5",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Training: Epoch 4/10', max=840.0, style=ProgressStyle(des…"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nEpoch 4: Total Loss 369.39713707940354\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0475b5b04b74aa9a615687f49e09f9b",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Training: Epoch 5/10', max=840.0, style=ProgressStyle(des…"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nEpoch 5: Total Loss 369.32800469533225\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba805d7c79447a2b411bedc4d52249b",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Training: Epoch 6/10', max=840.0, style=ProgressStyle(des…"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nEpoch 6: Total Loss 369.38085261336346\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b443842f494dd6be53f44314434bd1",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Training: Epoch 7/10', max=840.0, style=ProgressStyle(des…"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nEpoch 7: Total Loss 369.665073798173\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "155e02ae06634919b5fed3f17b4afc97",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Training: Epoch 8/10', max=840.0, style=ProgressStyle(des…"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nEpoch 8: Total Loss 369.4202830215182\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcca16f3d778466bb5901a52db952a79",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Training: Epoch 9/10', max=840.0, style=ProgressStyle(des…"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nEpoch 9: Total Loss 369.19014087901843\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9d1739a880244a99596279a59e474c5",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Training: Epoch 10/10', max=840.0, style=ProgressStyle(de…"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nEpoch 10: Total Loss 369.0909885830316\n"
    }
   ],
   "source": [
    "for epoch in range(config.TRAIN.EPOCHS):\n",
    "    model.train()\n",
    "    tq = tqdm(train_loader, total=len(train_loader), desc=f\"Training: Epoch {epoch+1}/{config.TRAIN.EPOCHS}\")\n",
    "    total_loss = 0\n",
    "\n",
    "    for _, batch in enumerate(tq):\n",
    "        model.zero_grad()\n",
    "        input_seq, output_seq = batch\n",
    "\n",
    "        input_seq = input_seq.to(device)\n",
    "        output_seq = output_seq.to(device)\n",
    "        loss = 0\n",
    "\n",
    "        # vectorize this\n",
    "        for c in range(config.TRAIN.MAX_LEN):\n",
    "            output = model(input_seq[:, c])\n",
    "            loss += loss_fn(output, output_seq[:, c])\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        # tq.set_postfix(loss=loss.item())\n",
    "        # batch-gradient-descent\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Total Loss {total_loss/(config.TRAIN.MAX_LEN * len(train_loader))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prime=\"B\", total_len=100, temp=0.5):\n",
    "    generated_text = prime\n",
    "\n",
    "    for p in range(len(prime) - 1):\n",
    "        input_char = torch.LongTensor(utils.char_to_label(prime[p])).to(device)\n",
    "        _ = model(input_char)\n",
    "\n",
    "    last_char = prime[-1]\n",
    "    \n",
    "    for c in range(total_len):\n",
    "        input_char = torch.LongTensor(utils.char_to_label(last_char)).to(device)\n",
    "        out = model(input_char)\n",
    "        out = out.view(-1).detach().cpu().div(temp).exp()\n",
    "        top_char = torch.multinomial(out, 1)[0]\n",
    "        predicted = string.printable[top_char]\n",
    "        generated_text += predicted\n",
    "        last_char = predicted\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"mankeng we the the me wery m inethe yot k ing sth istow yous ca thareyof pre whouseshe l be stho ther t the itheese t the, e fa, ara f wave meas us heth s the sther thend g t mo indeal, feat ton wanfoung re the, i thared n e oun a be wing y whe anomethe than routhe s thouere t i the ang whre ong t aianond w, lllat se ig g me wher s whe lling n m s the youghe, and se w, g an he the en ing as whe theelathe t ckend ind ar tge tahe l, y ideeri o, thang fe warond gare myo the he the fonar s int s in wayo it gon the te ou bote ha g y when wath s wan e bean mevend and ary the p be thed whane ber, he canu andi in hat windine w ang, ithi bor, myors o ry t, bin, ayofe, sthe are comide t therethon ta wayo s y be t thit yo t the tharuthe, t casin is yo istho st t bend t toushe ou mar hin youcho g le h min'me w sthe, t tin wane cor ur amangh, ongham a the thet lleno bel ithanengherenghithe ff m lo iner we t s the y ind m the i be ounginknou he 2 bal d llalo owh ve beve ingen ase gow, w win a ur nthet \""
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "generate(\"man\", 1000, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}